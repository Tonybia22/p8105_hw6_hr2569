---
title: "HW6"
author: "Hongzhu Ren"
date: "2023-12-01"
output: html_document
---
```{r setup,include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 2

Read in the data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

####Bootstrap
Use bootstrap to get the distribution for targeted value

```{r}
## extract concerning variables
weather_reg <- weather_df|>
  select(tmax,tmin,prcp)

## use bootstrap to generate sample
weather_bs <- weather_reg|>
  modelr::bootstrap(5000)|>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp,data = df)),
    Rsquare = map(models, broom::glance),
    beta = map(models, broom::tidy)
  )|>
  ## unnest result of broom::glance to get r square  
  select(Rsquare,beta)|>
  unnest(Rsquare)|>
  ## unnest result of broom::tidy to get beta1 and beta 2
  select(r.squared,beta)|>
  unnest(beta)|>
  ## get beta of tmin and beta of prcp for each bootstrap sample 
  select(r.squared,term,estimate)

weather_target <- weather_bs|>
  pivot_wider(
    names_from = term,
    values_from = estimate
  )|>
  ## calculate the targeted result
  mutate(
    log_beta1_beta2 = log(tmin*prcp)
  )|>
  ## get the distribution of targeted value
  select(r.squared,log_beta1_beta2)
```

#### Distribution of targeted values
Plot the bootsrap distribution for both $\hat{r}_*^2$ and $log(\hat{\beta}_1*\hat{\beta}_2)$

```{r}
weather_target |>
  select(r.squared)|>
  ggplot(aes(x = r.squared))+
  geom_density()+
  labs(
    title = "Density of 5000 bootstrap R^2"
  )


```

The distribution of $\hat{r}_*^2$ is close to normal distribution with little left skewness. The mean of r.square is `r weather_target |> pull(r.squared) |> mean()`, indicating a relatively well performed fit.

```{r}
weather_target |>
  select(log_beta1_beta2)|>
  ggplot(aes(x = log_beta1_beta2))+
  geom_density()+
  labs(
    title = "Density of 5000 bootstrap log(beta1*beta2)"
  )
```

The distribution of $log(\hat{\beta}_1*\hat{\beta}_2)$ is left skewed. The product of the coefficients of tmin and prcp is far below 1. We might consider the unit scale and the significance of the variable. The mean without NA is `r weather_target |> pull(log_beta1_beta2) |> mean(na.rm = TRUE)`. 


#### Construct CI for targeted value

```{r}
CI.rsquare <- c(
  CI.lower = weather_target |> pull(r.squared) |> quantile(.025),
  CI.upper = weather_target |> pull(r.squared) |> quantile(.975)
)

CI.log_beta <- c(
  CI.lower = weather_target |> pull(log_beta1_beta2) |> quantile(.025,na.rm = TRUE),
  CI.upper = weather_target |> pull(log_beta1_beta2) |> quantile(.975,na.rm = TRUE)
)
```

The CI for $\hat{r}_*^2$ is `r CI.rsquare`, the relative large value of $\hat{r}_*^2$ indicating a good model fit.

The CI for $log(\hat{\beta}_1*\hat{\beta}_2)$ after filtering out NA is `r CI.log_beta`. The value is far below 0, indicating a small scale of the product. This may arise from the difference in unit scale or the low correlation of one predictor.


# Problem 3

```{r}
nb_weight <- read_csv("./data/birthweight.csv")
```

Identify non-completed observations.

```{r}
complete <- nb_weight |> complete.cases()
nb_weight[!complete,]
```

It turns out that all cases are completed.

```{r}
nb_weight |> pull(pnumlbw)|>range()
nb_weight |> pull(pnumsga)|>range()
```

However,`pnumlbw` and `pnumsga` variables only have 0 value, which contributes nothing to our dependent variables. Therefore, I might take these two variables out. Also,we turn categorical values into factors

```{r}
weight_tidy <- nb_weight |>
  select(-pnumlbw,-pnumsga)|>
  mutate(
    babysex = factor(babysex, labels = c("male","female")),
    frace = case_match(frace,
      c(1) ~ "White",
      c(2) ~ "Black",
      c(3) ~ "Asian",
      c(4) ~ "Puerto Rican",
      c(8) ~ "Other",
      c(9) ~ "Unknown"
    ),
    mrace = case_when(
      mrace == 1 ~ "White",
      mrace == 2 ~ "Black",
      mrace == 3 ~ "Asian",
      mrace == 4 ~ "Puerto Rican",
      mrace == 8 ~ "Other"
    ),
    malform = case_match(malform,
      c(0) ~ "absent",
      c(1) ~ "present"
    )
  )
```

When further looking into data, I noticed something interesting.

```{r data_test}
weight_tidy |> pull(frace) |> unique()
weight_tidy |> pull(mrace) |> unique()

## Test if the wtgain variable is the difference between delwt and ppwt
weight_test <- weight_tidy|>
  mutate(
    weight_change = delwt - ppwt,
    delta = weight_change - wtgain
  )|>
  select(delta)|>
  range()

## The range of the delta equals 0,indicating wtgain variable is the difference between delwt and ppwt
weight_test
```

* First, the races of fathers only contains `r weight_tidy |> pull(frace) |> unique()`, in total `r weight_tidy |> pull(frace) |> unique() |> length()`races.
* Second, the races of mothers only contains `r weight_tidy |> pull(mrace) |> unique()`, in total `r weight_tidy |> pull(mrace) |> unique() |> length()`races.
* Third, the variable `wtgain` is the difference between `delwt` and `ppwt`. This direct linear relationship can allow me to delete `wtgain` variables for linear regression purpose.

Now generate the data for regression

```{r}
weight_reg <- weight_tidy|>
  select(-wtgain)
```

Get initial linear model

```{r}
model.0 <- lm(bwt ~ ., data = weight_reg)
```

Use AIC to select variables and read results

```{r}
model.AIC <- step(model.0)
summary(model.AIC)
```

Most fitted variables are significant, `r mraceBlack` and `r mracePuerto Rican` are not significant.

Then make plot of residuals and fitted values
```{r}
weight_predict <- weight_reg |>
  modelr::add_residuals(model.AIC)|>
  modelr::add_predictions(model.AIC)

weight_predict |>
  ggplot(aes(x = pred, y = resid))+
  geom_point()+
  geom_smooth()+
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "Residuals vs Fitted Values", 
    x = "Fitted Values", 
    y = "Residuals")
```

We can see that this model have a bad prediction when fitted values are relatively small. This may be due to the insignificant races
variables of the models.
The residuals has no significant patterns when the fitted values are around between 2000 to 4000. But overall the residuals are too big.


Then fit other two models

```{r}
model.1 <- lm(bwt ~ blength + gaweeks, data = weight_reg)
model.2 <- lm(bwt ~ bhead * blength * babysex, data = weight_reg)
```


```{r}
summary(model.1)
summary(model.2)
```

